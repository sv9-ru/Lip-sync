# Проект: Синхронизация губ (Lip-sync) с Wav2Lip и GFPGAN
  
Данный проект посвящен работе с нейросетями для синхронизации мимики лица с аудиодорожкой.  

**Используемые модели**  
* Wav2Lip — базовая модель синхронизации.  
* Wav2Lip-GFPGAN — улучшенная версия с реставрацией лиц.  
  
**Подготовка данных**
* используется запись говорящего человека (лицо четко в кадре, хорошее освещение).  
* 3 аудиодорожки (10-20 сек):

> Нативная английская речь.

> Нативная русская речь.

> Синтезированная речь (из задания по TTS).

## Вывод

Сравнение качества изображения (Wav2Lip vs Wav2Lip-GFPGAN)

Wav2Lip

Базовая модель демонстрирует заметную потерю четкости в области артикуляции. Это вызвано тем, что генерация происходит в низком разрешении ($96 \times 96$ пикселей), и при апскейлинге (растягивании) до размеров исходного кадра возникают размытость и артефакты на границах наложения.
  
![Видео](https://github.com/sv9-ru/Lip-sync/blob/main/results_Wav2Lip/ru_native_Wav2Lip_fixed.mp4) 

Wav2Lip-GFPGAN

Интеграция нейросети-реставратора GFPGAN позволяет восстановить детализацию. Модель реконструирует текстуру кожи, зубов и контуры губ, приводя разрешение сгенерированной области в соответствие с оригиналом.

![Видео](https://github.com/sv9-ru/Lip-sync/blob/main/results_GFPGAN/ru_native_HD_result.avi)

